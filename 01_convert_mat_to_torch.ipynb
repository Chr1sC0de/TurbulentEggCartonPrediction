{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.5 64-bit ('_env')",
   "display_name": "Python 3.7.5 64-bit ('_env')",
   "metadata": {
    "interpreter": {
     "hash": "7406eb72bae15db24ad7bd91c6e1faea0e695761500f4dfd69b8d19d5cede6c3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pt\n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "source": [
    "We can use the [pathlib](\"https://docs.python.org/3/library/pathlib.html\") library to read the files within a folder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mat_files\\wall_h20_l48.mat\n"
     ]
    }
   ],
   "source": [
    "current_folder = pt.Path(\".\")\n",
    "mat_folder = current_folder/\"mat_files\"\n",
    "mat_files = list(mat_folder.glob(\"*.mat\"))\n",
    "first_mat_file = mat_files[0]\n",
    "print(first_mat_file)"
   ]
  },
  {
   "source": [
    "The scipy.io function \"[loadmat](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html)\" will load the dictionary containing our mat data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'h', 'th', 'wss_z', 'z'])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data_dict = scio.loadmat(first_mat_file)\n",
    "data_dict.keys()"
   ]
  },
  {
   "source": [
    "We need to create a new dictionary which defines the inputs \"x\" and outputs \"y\" of our deep learning model. The inputs of the dictionary will be tensors of dimensions channels, height and width. First we will convert our data into torch tensors. We can do this for our data in one line using a [dictioanry comprehension](https://www.programiz.com/python-programming/dictionary-comprehension)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensor_data = {key: torch.from_numpy(data) for key, data in data_dict.items() if not key.startswith(\"_\")}"
   ]
  },
  {
   "source": [
    "Now we can stack our data data with a a [list comprehension](https://www.programiz.com/python-programming/list-comprehension) and expand our output tensor so that we obtain tensors of the correct shape"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 541, 864]) torch.Size([1, 541, 864])\n"
     ]
    }
   ],
   "source": [
    "input_feature_names = [\"h\", \"th\", \"z\"]\n",
    "x = torch.stack([torch_tensor_data[key] for key in input_feature_names])\n",
    "y = torch_tensor_data[\"wss_z\"][None, :]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "source": [
    "Now that we know how to process the data let's create a function wich process our mat files into torch data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_to_torch(\n",
    "    mat_path, \n",
    "    input_feature_names=[\"h\", \"th\", \"z\"],\n",
    "    output_feature_names=[\"wss_z\"]\n",
    "): \n",
    "    data_dict = scio.loadmat(first_mat_file)\n",
    "    torch_tensor_data = {key: torch.from_numpy(data) for key, data in data_dict.items       () if not key.startswith(\"_\")}\n",
    "    x = torch.stack([torch_tensor_data[key] for key in input_feature_names])\n",
    "    y = torch.stack([torch_tensor_data[key] for key in output_feature_names])\n",
    "    if len(x.shape) == 2: x=x[None,:]\n",
    "    if len(y.shape) == 2: y=y[None,:]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = mat_to_torch(first_mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 541, 864]) torch.Size([1, 541, 864])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "source": [
    "Now we can process all the data and save them into our torch folder as single files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_folder = current_folder/\"torch_files\"\n",
    "for path in mat_files:\n",
    "    x,y = mat_to_torch(path)\n",
    "    torch.save(\n",
    "        {\n",
    "            \"x\":x,\n",
    "            \"y\":y\n",
    "        },\n",
    "       torch_folder/path.stem\n",
    "    )"
   ]
  }
 ]
}