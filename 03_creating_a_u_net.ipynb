{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.5 64-bit ('_env')",
   "display_name": "Python 3.7.5 64-bit ('_env')",
   "metadata": {
    "interpreter": {
     "hash": "7406eb72bae15db24ad7bd91c6e1faea0e695761500f4dfd69b8d19d5cede6c3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "source": [
    "In this example we will be creating a [U-net](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47#:~:text=The%20UNET%20was%20developed%20by,The%20architecture%20contains%20two%20paths.&text=Thus%20it%20is%20an%20end,accept%20image%20of%20any%20size.) model for predicting our wall shear stress. A U-net is an example of a [convolutional neural network](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/).\n",
    "\n",
    "First we will create the base building block of our neural network, a simple block containing a [convolutions](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/), [batch normalization](https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c) and an ReLU [activation function](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNormAct(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=\"same\", **kwargs):\n",
    "        super().__init__()\n",
    "        if padding == \"same\":\n",
    "            assert kernel_size//2 == 1\n",
    "            padding = kernel_size//2\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, **kwargs)\n",
    "        self.bnorm = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.bnorm(self.conv(x)))"
   ]
  },
  {
   "source": [
    "Bellow we show a simple example of the layer we created taking in an input with 3 features and creating an output with 6 features. Finally we can pass the output through a [max pooling](https://computersciencewiki.org/index.php/Max-pooling_/_Pooling#:~:text=Max%20pooling%20is%20a%20sample,in%20the%20sub%2Dregions%20binned.) layer to reduce the size."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 6, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3,  256, 256)\n",
    "layer = ConvNormAct(3, 6, 3)\n",
    "pool = torch.nn.MaxPool2d(2)\n",
    "output = pool(layer(x))\n",
    "print(x.shape, output.shape)"
   ]
  },
  {
   "source": [
    "Now we need to create an upsamping layer for our data. We will use upsample convolutions, as they generally converge faster than simple transposed convolutions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleConv(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, **kwargs):\n",
    "        super().__init__()\n",
    "        self.upsample = torch.nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.conv = ConvNormAct(in_channels, out_channels, kernel_size, **kwargs)\n",
    "    def forward(self,x):\n",
    "        return self.conv(self.upsample(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "upsample_layer = UpsampleConv(6,3)\n",
    "print(upsample_layer(output).shape)"
   ]
  },
  {
   "source": [
    "Now we have the tools to create our simple u-net model. We will make a relatively shallow network and visualize it using [tensorboard](https://www.tensorflow.org/tensorboard) for pytorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, base_channels=64, kernel_size=3):\n",
    "        super().__init__()\n",
    "        ConvWrapped = partial(ConvNormAct, kernel_size=3)\n",
    "        # encoding layers\n",
    "        self.conv1a = ConvWrapped(in_channels, base_channels)\n",
    "        self.conv1b = ConvWrapped(base_channels, base_channels)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(2)\n",
    "        self.conv2a = ConvWrapped(base_channels, 2*base_channels)\n",
    "        self.conv2b = ConvWrapped(2*base_channels, 2*base_channels)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(2)\n",
    "        self.conv3a = ConvWrapped(2*base_channels, 4*base_channels)\n",
    "        self.conv3b = ConvWrapped(4*base_channels, 4*base_channels)\n",
    "        # deconding layers\n",
    "        self.upsample_1 = UpsampleConv(4*base_channels, 2*base_channels)\n",
    "        self.conv4a = ConvWrapped(4*base_channels, 2*base_channels)\n",
    "        self.conv4b = ConvWrapped(2*base_channels, 2*base_channels)\n",
    "        self.upsample_2 = UpsampleConv(2*base_channels, base_channels)\n",
    "        self.conv5a = ConvWrapped(2*base_channels, base_channels)\n",
    "        self.conv5b = ConvWrapped(base_channels, base_channels)\n",
    "        self.output_conv = torch.nn.Conv2d(base_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1a(x)\n",
    "        x = self.conv1b(x)\n",
    "        c1 = x\n",
    "        x = self.pool_1(x)\n",
    "        x = self.conv2a(x)\n",
    "        x = self.conv2b(x)\n",
    "        c2 = x\n",
    "        x = self.pool_2(x)\n",
    "        x = self.conv3a(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = self.upsample_1(x)\n",
    "        x = torch.cat([x, c2], dim=1)\n",
    "        x = self.conv4a(x)\n",
    "        x = self.conv4b(x)\n",
    "        x = self.upsample_2(x)\n",
    "        x = torch.cat([x, c1], dim=1)\n",
    "        x = self.conv5a(x)\n",
    "        x = self.conv5b(x)\n",
    "        return self.output_conv(x)\n",
    "\n"
   ]
  },
  {
   "source": [
    "Now to visualize the created network with tensorboard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a summary writer for tensorboard\n",
    "writer = SummaryWriter('runs/view_model')\n",
    "# create a dummy input\n",
    "x = torch.randn(1, 3,  256, 256)\n",
    "# construct the model and pass the input through it\n",
    "model = UNet(3, 1)\n",
    "# add the graph to tensorboard and close the writer\n",
    "writer.add_graph(model, x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tensorbaord extension\n",
    "%load_ext tensorboard\n",
    "# run tensorboard, if it does not work, we can try running the command in the terminal after moving to the required directory\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}